{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1000000, 2000000, 3000000, 4000000, 4459760, 5459760, 6459760, 7459760, 8459760, 8919520, 9919520, 10919520, 11919520, 12919520, 13379280, 14379280, 15379280, 16379280, 17379280, 17839040]\n",
      "[0, 1000000, 2000000, 3000000, 4000000, 4459759, 5459759, 6459759, 7459759, 8459759, 8919518, 9919518, 10919518, 11919518, 12919518, 13379277, 14379277, 15379277, 16379277, 17379277, 17839036]\n"
     ]
    }
   ],
   "source": [
    "indices1 = [0]\n",
    "\n",
    "cur = 0\n",
    "for i in range(0, 20):\n",
    "    if (i + 1) % 5 == 0:\n",
    "        cur += 459_760\n",
    "    else:\n",
    "        cur += 1_000_000\n",
    "    indices1.append(cur)\n",
    "\n",
    "print(indices1)\n",
    "# Create 2-tuples of the form (start, end)\n",
    "ranges1 = [(indices1[i], indices1[i + 1], indices1[i + 1] - indices1[i]) for i in range(0, 20)]\n",
    "\n",
    "indices2 = [0]\n",
    "\n",
    "cur = 0\n",
    "for i in range(0, 20):\n",
    "    # if i == 4 or i == 9:\n",
    "    #     cur += 459_759\n",
    "    if (i + 1) % 5 == 0:\n",
    "        cur += 459_759\n",
    "    else:\n",
    "        cur += 1_000_000\n",
    "    indices2.append(cur)\n",
    "\n",
    "print(indices2)\n",
    "# Create 2-tuples of the form (start, end)\n",
    "ranges2 = [(indices2[i], indices2[i + 1], indices2[i + 1] - indices2[i]) for i in range(0, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_embeddings = [\n",
    "    torch.zeros((indices1[-1] + 1, 1024), dtype=torch.float16, device='cuda:0'),\n",
    "    torch.zeros((indices2[-1], 1024), dtype=torch.float16, device='cuda:1')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del split_embeddings\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_paths = [\n",
    "    f'/burg/dsi/users/jef2182/data/e5-large-index/e5-large-shard-{i}.pt' for i in range(0, 40)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 0\n",
      "(0, 1000000)\n",
      "Loading shard 1\n",
      "(1000000, 2000000)\n",
      "Loading shard 2\n",
      "(2000000, 3000000)\n",
      "Loading shard 3\n",
      "(3000000, 4000000)\n",
      "Loading shard 4\n",
      "(4000000, 4459760)\n",
      "Loading shard 5\n",
      "(4459760, 5459760)\n",
      "Loading shard 6\n",
      "(5459760, 6459760)\n",
      "Loading shard 7\n",
      "(6459760, 7459760)\n",
      "Loading shard 8\n",
      "(7459760, 8459760)\n",
      "Loading shard 9\n",
      "(8459760, 8919520)\n",
      "Loading shard 10\n",
      "(8919520, 9919520)\n",
      "Loading shard 11\n",
      "(9919520, 10919520)\n",
      "Loading shard 12\n",
      "(10919520, 11919520)\n",
      "Loading shard 13\n",
      "(11919520, 12919520)\n",
      "Loading shard 14\n",
      "(12919520, 13379280)\n",
      "Loading shard 15\n",
      "(13379280, 14379280)\n",
      "Loading shard 16\n",
      "(14379280, 15379280)\n",
      "Loading shard 17\n",
      "(15379280, 16379280)\n",
      "Loading shard 18\n",
      "(16379280, 17379280)\n",
      "Loading shard 19\n",
      "(17379280, 17839040)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f'Loading shard {i}')\n",
    "    print(f'{(ranges1[i][0], ranges1[i][1])}')\n",
    "    split_embeddings[0][ranges1[i][0]:ranges1[i][1]] = torch.load(shard_paths[i], map_location=torch.device(\"cuda:0\"), weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shard 20\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 21\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 22\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 23\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 24\n",
      "torch.Size([459759, 1024])\n",
      "Loading shard 25\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 26\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 27\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 28\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 29\n",
      "torch.Size([459759, 1024])\n",
      "Loading shard 30\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 31\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 32\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 33\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 34\n",
      "torch.Size([459759, 1024])\n",
      "Loading shard 35\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 36\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 37\n",
      "torch.Size([1000000, 1024])\n",
      "Loading shard 38\n",
      "torch.Size([1000000, 1024])\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,39):\n",
    "    print(f'Loading shard {i}')\n",
    "    shard = torch.load(shard_paths[i], map_location=torch.device(\"cuda:0\"), weights_only=True)\n",
    "    print(shard.shape)\n",
    "    split_embeddings[1][ranges2[i-20][0]:ranges2[i-20][1]] = shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 1024])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/burg/dsi/users/jef2182/data/e5-large-index/e5-large-shard-38.pt', weights_only=True, map_location=torch.device('cuda:0')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([459760, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/burg/dsi/users/jef2182/data/e5-large-index/e5-large-shard-4.pt', weights_only=True, map_location=torch.device('cuda:0')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([459760, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/burg/dsi/users/jef2182/data/e5-large-index/e5-large-shard-19.pt', weights_only=True, map_location=torch.device('cuda:0')).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
